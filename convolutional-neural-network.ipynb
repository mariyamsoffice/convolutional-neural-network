{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "859f5062",
   "metadata": {},
   "source": [
    "# Convolutional Neural Network Using Python (Image Classification)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce37fa7c",
   "metadata": {},
   "source": [
    "# Importing requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "7b99f0da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbd5cb2a",
   "metadata": {},
   "source": [
    "# Importing a Keras dataset called 'CIFAR10'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1a265827",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.cs.toronto.edu/~kriz/cifar.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9b8c61e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar10 = keras.datasets.cifar10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e8398c61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'keras.api._v2.keras.datasets.cifar10' from 'C:\\\\Users\\\\DeLL\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python310\\\\lib\\\\site-packages\\\\keras\\\\api\\\\_v2\\\\keras\\\\datasets\\\\cifar10\\\\__init__.py'>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cifar10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "fe1e59e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_images, train_labels), (test_images, test_labels) = cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c39a0e26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 32, 32, 3)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a5b2d849",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images, test_images = train_images / 255.0, test_images / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "82ebf123",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b9e4b6f",
   "metadata": {},
   "source": [
    "# Applying Keras' Sequential Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9563efba",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f818d2b",
   "metadata": {},
   "source": [
    "# Applying a 2-Dimensional Convolutional Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a235ab74",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(layers.Conv2D(32, (3,3), strides = (1,1), padding = 'valid', activation = 'relu', input_shape = (32, 32, 3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e59aa166",
   "metadata": {},
   "source": [
    "# Applying a Pooling Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b0324e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(layers.MaxPool2D((2,2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14005495",
   "metadata": {},
   "source": [
    "# Applying the second 2-Dimensional Convolutional Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0025d772",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(layers.Conv2D(32, 3, activation = 'relu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c12f9d39",
   "metadata": {},
   "source": [
    "# Applying the second 2-Dimensional Convolutional Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6fc848d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(layers.MaxPool2D((2,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b8ef9e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(layers.Flatten())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95330da4",
   "metadata": {},
   "source": [
    "# Adding a Dense Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "6063c3cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(layers.Dense(64, activation = 'relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "3f56ca99",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(layers.Dense(10)) # Using 10 since we have 10 output classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68da9812",
   "metadata": {},
   "source": [
    "# Model Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "4d5ae14a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_2 (Conv2D)           (None, 30, 30, 32)        896       \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 15, 15, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 13, 13, 32)        9248      \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 6, 6, 32)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 1152)              0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 64)                73792     \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 10)                650       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 84,586\n",
      "Trainable params: 84,586\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f388b2d",
   "metadata": {},
   "source": [
    "# Loss and Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "0ef55b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = keras.losses.SparseCategoricalCrossentropy(from_logits = True)\n",
    "optim = keras.optimizers.Adam(lr = 0.001)\n",
    "metrics = ['accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c4d91736",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = optim, loss = loss, metrics = metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93f1e5b0",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "09ab1546",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "epochs = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "77c1bd81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "782/782 - 47s - loss: 1.5777 - accuracy: 0.4318 - 47s/epoch - 60ms/step\n",
      "Epoch 2/20\n",
      "782/782 - 47s - loss: 1.2588 - accuracy: 0.5547 - 47s/epoch - 60ms/step\n",
      "Epoch 3/20\n",
      "782/782 - 45s - loss: 1.1213 - accuracy: 0.6080 - 45s/epoch - 57ms/step\n",
      "Epoch 4/20\n",
      "782/782 - 45s - loss: 1.0308 - accuracy: 0.6424 - 45s/epoch - 58ms/step\n",
      "Epoch 5/20\n",
      "782/782 - 43s - loss: 0.9683 - accuracy: 0.6646 - 43s/epoch - 56ms/step\n",
      "Epoch 6/20\n",
      "782/782 - 44s - loss: 0.9141 - accuracy: 0.6842 - 44s/epoch - 56ms/step\n",
      "Epoch 7/20\n",
      "782/782 - 45s - loss: 0.8783 - accuracy: 0.6977 - 45s/epoch - 58ms/step\n",
      "Epoch 8/20\n",
      "782/782 - 44s - loss: 0.8391 - accuracy: 0.7088 - 44s/epoch - 57ms/step\n",
      "Epoch 9/20\n",
      "782/782 - 47s - loss: 0.8049 - accuracy: 0.7220 - 47s/epoch - 60ms/step\n",
      "Epoch 10/20\n",
      "782/782 - 46s - loss: 0.7785 - accuracy: 0.7307 - 46s/epoch - 59ms/step\n",
      "Epoch 11/20\n",
      "782/782 - 46s - loss: 0.7527 - accuracy: 0.7391 - 46s/epoch - 59ms/step\n",
      "Epoch 12/20\n",
      "782/782 - 46s - loss: 0.7276 - accuracy: 0.7500 - 46s/epoch - 59ms/step\n",
      "Epoch 13/20\n",
      "782/782 - 46s - loss: 0.7019 - accuracy: 0.7559 - 46s/epoch - 59ms/step\n",
      "Epoch 14/20\n",
      "782/782 - 45s - loss: 0.6793 - accuracy: 0.7650 - 45s/epoch - 57ms/step\n",
      "Epoch 15/20\n",
      "782/782 - 45s - loss: 0.6609 - accuracy: 0.7695 - 45s/epoch - 57ms/step\n",
      "Epoch 16/20\n",
      "782/782 - 46s - loss: 0.6480 - accuracy: 0.7751 - 46s/epoch - 59ms/step\n",
      "Epoch 17/20\n",
      "782/782 - 44s - loss: 0.6258 - accuracy: 0.7833 - 44s/epoch - 56ms/step\n",
      "Epoch 18/20\n",
      "782/782 - 46s - loss: 0.6139 - accuracy: 0.7858 - 46s/epoch - 59ms/step\n",
      "Epoch 19/20\n",
      "782/782 - 46s - loss: 0.5929 - accuracy: 0.7937 - 46s/epoch - 59ms/step\n",
      "Epoch 20/20\n",
      "782/782 - 46s - loss: 0.5772 - accuracy: 0.8005 - 46s/epoch - 59ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x28b7d7ef700>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_images, train_labels, epochs = epochs, batch_size = batch_size, verbose = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b303a30",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "c966794a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "5d250501",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing what class the 3rd image in the dataset falls into"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "b30702e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 32ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(model.predict(np.expand_dims(test_images[2], axis = 0)).round(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "8ec82f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing what class the 4678th image in the dataset falls into"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "7fb87d9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 24ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(model.predict(np.expand_dims(test_images[4677], axis = 0)).round(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76f214fd",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "94770d41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 - 2s - loss: 0.9687 - accuracy: 0.6939 - 2s/epoch - 10ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.968704104423523, 0.6938999891281128]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_images, test_labels, batch_size = batch_size, verbose = 2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
